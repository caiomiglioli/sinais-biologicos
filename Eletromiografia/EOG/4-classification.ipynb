{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, RFE, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 560, 18)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.load(\"processed/extracted_features.npy\").swapaxes(1,2)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# protocolo\n",
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "\n",
    "# criação do vetor de labels final\n",
    "# y = labels_num * int(features.shape[1] / len(labels_num))\n",
    "# print(y)\n",
    "# len(y)\n",
    "\n",
    "y = np.repeat(labels_num, int(features.shape[1] / len(labels_num)), axis=None)\n",
    "print(y)\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 3*: Realização da normalização dos dados utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicando normalização\n",
    "\n",
    "for i in range(len(features)):\n",
    "  features[i] = StandardScaler().fit_transform(features[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 4*: Realização da seleção de características, utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 9)\n",
      "(560, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/.local/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [0 1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/caio/.local/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 9)\n",
      "(560, 9)\n",
      "(560, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/.local/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [0 1] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/caio/.local/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(560, 9)\n"
     ]
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "X_all = list()\n",
    "\n",
    "threshold = .1\n",
    "k = 9\n",
    "n_components = 6\n",
    "\n",
    "\n",
    "for i in range(len(features)):\n",
    "  # SELECT K BEST\n",
    "  kb = SelectKBest(f_classif, k=k).fit_transform(features[i], y)\n",
    "  X_all.append((f'p{i}-kBest', kb))\n",
    "  print(kb.shape)\n",
    "\n",
    "  # VARIANCE THRESHOLD\n",
    "  vt = VarianceThreshold(threshold).fit_transform(features[i])\n",
    "  X_all.append((f'p{i}-vTresh', vt))\n",
    "  print(vt.shape)\n",
    "\n",
    "  # RECURSIVE FEATURE ELIMINATION\n",
    "  rfe = RFE(svm.SVC(kernel=\"linear\")).fit_transform(features[i], y)\n",
    "  X_all.append((f'p{i}-RFE', rfe))\n",
    "  print(rfe.shape)\n",
    "\n",
    "  # # PRINCIPAL COMPONENT ANALISYS\n",
    "  # pca = PCA(n_components).fit_transform(features[i])\n",
    "  # X_all.append((f'p{i}-PCA', pca))\n",
    "  # print(pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 5*: Realização da classificação utilizando `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0-kBest --------------------------------------------\n",
      "Treino > (448, 9) 448\n",
      "Teste > (112, 9) 112\n",
      "Acurácia > 0.4375 \n",
      "\n",
      "p0-vTresh --------------------------------------------\n",
      "Treino > (448, 16) 448\n",
      "Teste > (112, 16) 112\n",
      "Acurácia > 0.45535714285714285 \n",
      "\n",
      "p0-RFE --------------------------------------------\n",
      "Treino > (448, 9) 448\n",
      "Teste > (112, 9) 112\n",
      "Acurácia > 0.49107142857142855 \n",
      "\n",
      "p1-kBest --------------------------------------------\n",
      "Treino > (448, 9) 448\n",
      "Teste > (112, 9) 112\n",
      "Acurácia > 0.25 \n",
      "\n",
      "p1-vTresh --------------------------------------------\n",
      "Treino > (448, 16) 448\n",
      "Teste > (112, 16) 112\n",
      "Acurácia > 0.3125 \n",
      "\n",
      "p1-RFE --------------------------------------------\n",
      "Treino > (448, 9) 448\n",
      "Teste > (112, 9) 112\n",
      "Acurácia > 0.25 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "for X in X_all:\n",
    "    print(f'{X[0]} --------------------------------------------')\n",
    "    # Divisão Treino/Teste\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X[1], y, test_size=0.2, random_state=42)\n",
    "    print('Treino >', x_train.shape, len(y_train))\n",
    "    print('Teste >', x_test.shape, len(y_test))\n",
    "    \n",
    "    # Grid search\n",
    "    # param_grid = {\n",
    "    #     'C': [0.1, 1, 10, 100],\n",
    "    #     'kernel': ['linear', 'rbf', 'poly'],#, 'sigmoid'],\n",
    "    #     'gamma': [0.01, 0.1, 1, 10],\n",
    "    #     # 'degree': [2, 3, 4],\n",
    "    #     # 'coef0': [0, 0.5, 1],\n",
    "    #     # 'tol': [1e-4, 1e-5, 1e-6]\n",
    "    # }\n",
    "   \n",
    "    param_grid = [\n",
    "        {'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "        {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['linear', 'rbf', 'poly']},\n",
    "    ]\n",
    "\n",
    "    grid = GridSearchCV(svm.SVC(), param_grid, cv=5)\n",
    "    grid.fit(x_train, y_train)\n",
    "\n",
    "    # Predição\n",
    "    y_pred = grid.predict(x_test)\n",
    "    print('Acurácia >', metrics.accuracy_score(y_test, y_pred), '\\n')\n",
    "    # print(metrics.classification_report(y_test, y_pred, digits=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
